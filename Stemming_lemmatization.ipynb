{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "QdYX32_EKu-s",
        "Yj_R79CTBbWf"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cSL59C1zkTH"
      },
      "source": [
        "#**Tallo (stemming) y Lematización (lemmatization)**\n",
        "\n",
        "###Para implementar las técnicas de tallado (stemming) y lematización (lemmatization) existe una gran variedad de librerías para implementar. \n",
        "\n",
        "###Recordemos que ambas técnicas tratan de normalizar o etandarizar un conjunto de palabras a una secuencia de caracteres raíz (en el caso de stemming) o a la palabra lema. En ambos casos, se trata de ese token estandarizado que estará representando a otro conjunto de tokens o palabras.\n",
        "\n",
        "###Veamos unos ejemplos para clarificar los conceptos."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Métodos para extracción de la secuencia raíz o tallo (stemming)**"
      ],
      "metadata": {
        "id": "QdYX32_EKu-s"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nVB6R9y82S9"
      },
      "source": [
        "## **Porter stemming algorithm**\n",
        "\n",
        "### uno de los más populares algoritmos en inglés desarrollado por Martin Porter: https://tartarus.org/martin/PorterStemmer/   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "393ztBiDzVwN"
      },
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer   "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('omw-1.4')   # paquete de nltk que ayuda en el proceso de stemming y lemmatization."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Efo0UJEdG-6",
        "outputId": "af0fa2b8-97a2-443e-f47c-630510a0ff0b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QREEl0rB3Ux9"
      },
      "source": [
        "# creamos un objeto de la clase PorterStemmer\n",
        "ps = PorterStemmer()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsHCN8ug0-Jc",
        "outputId": "f5522c8d-5217-416a-97fd-3f5cfbfcf086"
      },
      "source": [
        "# Verbo regular:\n",
        "x = ['visits', 'visited', 'visiting']\n",
        "\n",
        "[ps.stem(w) for w in x]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['visit', 'visit', 'visit']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21PVPjNj4S4d",
        "outputId": "ca995759-b739-4c49-809b-975c6667327d"
      },
      "source": [
        "# Verbo irregular:\n",
        "y = ['fall', 'fell', 'fallen', 'falling', 'ring', 'rang', 'rung', 'ringing', 'come', 'came', 'coming', 'built']\n",
        "\n",
        "print([ps.stem(w) for w in y])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fall', 'fell', 'fallen', 'fall', 'ring', 'rang', 'rung', 'ring', 'come', 'came', 'come', 'built']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKpE0Kc85cZG",
        "outputId": "a17b44fc-5f22-47f2-dd49-e9054d923414"
      },
      "source": [
        "# otro tipo de palabras...\n",
        "z = ['strange', 'dogs', 'beautiful', 'amazing', 'cats', 'terminator', 'carefully', 'eldest', 'farthest', 'further', 'queries', 'waterbed']\n",
        "\n",
        "print([ps.stem(w) for w in z])\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['strang', 'dog', 'beauti', 'amaz', 'cat', 'termin', 'care', 'eldest', 'farthest', 'further', 'queri', 'waterb']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6vbrUyL89Hc"
      },
      "source": [
        "## **Lancaster - Paice/Husk stemming algorithm**\n",
        "\n",
        "#### Algoritmo desarrollado por Chris D. Paice en la Universidad de Lancaster. \n",
        "\n",
        "https://dl.acm.org/doi/pdf/10.1145/101306.101310\n",
        "\n",
        "Generalmente reduce más la longitud de una palabra y es más rápido en general. Podemos decir que es \"más agresivo\" en relación a otros algoritmos, aunque esto pueda generar luego problemas en la interpretación o significado de las salidas generadas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qer94dYq9I-p"
      },
      "source": [
        "from nltk.stem import LancasterStemmer"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agZuCoF69om0"
      },
      "source": [
        "ls = LancasterStemmer()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_w6JaCi59yFU",
        "outputId": "5ce95cea-0b87-4e01-f28c-d340cdb0fdf2"
      },
      "source": [
        "x = ['visits', 'visited', 'visiting']\n",
        "\n",
        "[ls.stem(w) for w in x]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['visit', 'visit', 'visit']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01F3Qf-191t7",
        "outputId": "d4af6617-0066-4c6a-f95f-66d5cfb228d4"
      },
      "source": [
        "y = ['fall', 'fell', 'fallen', 'falling', 'ring', 'rang', 'rung', 'ringing', 'come', 'came', 'coming', 'built', 'were']\n",
        "\n",
        "print([ls.stem(w) for w in y])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fal', 'fel', 'fal', 'fal', 'ring', 'rang', 'rung', 'ring', 'com', 'cam', 'com', 'built', 'wer']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjNjsRAI-BA0",
        "outputId": "17f2185a-f147-4b1b-de77-56f566045b4e"
      },
      "source": [
        "z = ['strange', 'dogs', 'beautiful', 'amazing', 'cats', 'terminator', 'carefully', 'eldest', 'farthest', 'further', 'queries', 'waterbed']\n",
        "\n",
        "print([ls.stem(w) for w in z])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['strange', 'dog', 'beauty', 'amaz', 'cat', 'termin', 'car', 'eldest', 'farthest', 'furth', 'query', 'waterb']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbGiKTkTwgKZ"
      },
      "source": [
        "## **RegexpStemmer stemming algorithm**\n",
        "\n",
        "### **Rule-base-method**: Lo interesante de este modelo es que puedes construir tus propias reglas y complementarlo con alguno de los otros algoritmos.\n",
        "\n",
        "Puedes consultar su documentación para mayor información:\n",
        "\n",
        "https://www.nltk.org/_modules/nltk/stem/regexp.html \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqOVuooPwxaA"
      },
      "source": [
        "from nltk.stem import RegexpStemmer"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "La3-0oflxUPJ"
      },
      "source": [
        "# min : longitud mínima del string para que se aplique la regla:\n",
        "rs = RegexpStemmer(r'ing$|ed$|s$|t$', min=3)   # definimos la regla deseada construyendo un objeto de RegexpStemmer()."
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "859Gfw84yP4w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e931f27a-7681-4b6c-b00e-91a5a7950dc0"
      },
      "source": [
        "x = ['visits', 'visited', 'visiting']\n",
        "\n",
        "[rs.stem(w) for w in x]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['visit', 'visit', 'visit']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAfavbdXyWAa",
        "outputId": "7589c364-e6a3-4688-d962-c0fcffea09ce"
      },
      "source": [
        "y = ['fall', 'fell', 'fallen', 'falling', 'ring', 'rang', 'rung', 'ringing', 'come', 'came', 'coming', 'built', 'were']\n",
        "\n",
        "print([rs.stem(w) for w in y])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fall', 'fell', 'fallen', 'fall', 'r', 'rang', 'rung', 'ring', 'come', 'came', 'com', 'buil', 'were']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Zqk8cAuygjw",
        "outputId": "c030d0ba-a47b-4100-d119-ccfe8d41d508"
      },
      "source": [
        "z = ['strange', 'dogs', 'beautiful', 'amazing', 'cats', 'terminator', 'carefully', 'eldest', 'farthest', 'further', 'queries', 'waterbed']\n",
        "\n",
        "print([rs.stem(w) for w in z])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['strange', 'dog', 'beautiful', 'amaz', 'cat', 'terminator', 'carefully', 'eldes', 'farthes', 'further', 'querie', 'waterb']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Evd9wbyt38sI"
      },
      "source": [
        "### Podemos crear nuestras propias reglas en **Español** con RegexpStemmer, ya que no depende estrictamente de algún idioma en particular:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4KvWi364D9J"
      },
      "source": [
        "srs = RegexpStemmer('ron$|ste$|é|ando|ar$', min=5)  "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgGE6LGZ4gNQ",
        "outputId": "48174f6e-b226-4174-8205-968ed61f4e41"
      },
      "source": [
        "x = ['jugar', 'jugando', 'jugué', 'jugaste', 'caminé', 'almorcé', 'fué', 'fueron', 'fuiste', 'aceptar', 'aceptó', 'aceptaron', 'reiste']\n",
        "\n",
        "print([srs.stem(w) for w in x])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['jug', 'jug', 'jugu', 'juga', 'camin', 'almorc', 'fué', 'fue', 'fui', 'acept', 'aceptó', 'acepta', 'rei']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_GVf_ebzCDR"
      },
      "source": [
        "## **Snowball - Porter2 stemming algorithm**\n",
        "\n",
        "### Es un algoritmo que mejora el algoritmo de Porter, principalmente en cuanto al tiempo de cómputo. \n",
        "\n",
        "###Pero la principal diferencia es que soporta diferentes idiomas, entre ellos el **Español**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihk3HlEe0jh5"
      },
      "source": [
        "from nltk.stem import SnowballStemmer"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wV87iCk7caQg",
        "outputId": "34fbb71d-e47b-426f-95cb-9f40229f5c4c"
      },
      "source": [
        "print(SnowballStemmer.languages)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('arabic', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'hungarian', 'italian', 'norwegian', 'porter', 'portuguese', 'romanian', 'russian', 'spanish', 'swedish')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2zFoVQx0_Dw"
      },
      "source": [
        "ss = SnowballStemmer(\"english\")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTWmLOLX1ydh",
        "outputId": "9d7c8efd-ee40-4134-a46b-da52381e1a75"
      },
      "source": [
        "x = ['visits', 'visited', 'visiting']\n",
        "\n",
        "[ss.stem(w) for w in x]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['visit', 'visit', 'visit']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etcz4GCM11zo",
        "outputId": "aca9df6b-d7a1-40ea-ad54-ead41a86c28a"
      },
      "source": [
        "y = ['fall', 'fell', 'fallen', 'falling', 'ring', 'rang', 'rung', 'ringing', 'come', 'came', 'coming', 'built', 'were']\n",
        "\n",
        "print([ss.stem(w) for w in y])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fall', 'fell', 'fallen', 'fall', 'ring', 'rang', 'rung', 'ring', 'come', 'came', 'come', 'built', 'were']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9EXplA619ds",
        "outputId": "2611d3d9-91ec-4dc0-e8e6-870975dd224b"
      },
      "source": [
        "z = ['strange', 'dogs', 'beautiful', 'amazing', 'cats', 'terminator', 'carefully', 'eldest', 'farthest', 'further', 'queries', 'waterbed']\n",
        "\n",
        "print([ss.stem(w) for w in z])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['strang', 'dog', 'beauti', 'amaz', 'cat', 'termin', 'care', 'eldest', 'farthest', 'further', 'queri', 'waterb']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xExutVXp2Pof"
      },
      "source": [
        "### **Veamos algunos casos en Español:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqzeh4tT2TQI"
      },
      "source": [
        "sss = SnowballStemmer(\"spanish\")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwUovJmM2XaA",
        "outputId": "c5ff465b-2f92-40ae-88df-baeb763240c8"
      },
      "source": [
        "x = ['jugar', 'jugando', 'jugué', 'jugaste', 'jugo', 'caminé', 'almorcé', 'fué', 'fueron', 'fuiste', 'aceptar', 'aceptó', 'aceptaron', 'aceptaste']\n",
        "\n",
        "print([sss.stem(w) for w in x])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['jug', 'jug', 'jug', 'jug', 'jug', 'camin', 'almorc', 'fue', 'fueron', 'fuist', 'acept', 'acept', 'acept', 'acept']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# veamos cómo lo hace con un verbo irregular:\n",
        "\n",
        "x = ['hacer', 'hace', 'hizo', 'hiciste', 'hicieron', 'hacéis', 'hacemos', 'hacía', 'haremos', 'haré', 'hecho', 'hagamos', 'haríamos']\n",
        "\n",
        "print([sss.stem(w) for w in x])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c726NWzY8Jpg",
        "outputId": "4c4640ad-ee0d-4e9c-ab58-3b28b6e51c67"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hac', 'hac', 'hiz', 'hic', 'hic', 'hac', 'hac', 'hac', 'har', 'har', 'hech', 'hag', 'har']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = ['felizmente', 'felicidades', 'grandioso', 'mejorando', 'mejorado', 'gatos', 'carísimo', 'artistas', 'rápidamente']\n",
        "\n",
        "print([sss.stem(w) for w in x])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NVWADhRJbwN",
        "outputId": "75079593-cbc3-4360-d5cf-8b3bdeeac0ec"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['feliz', 'felic', 'grandios', 'mejor', 'mejor', 'gat', 'carisim', 'artist', 'rapid']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yj_R79CTBbWf"
      },
      "source": [
        "#**Métodos para extracción del lema o lematización (lemmatization)**\n",
        "\n",
        "### Se requiere de la base de datos de WordNet "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aM9UpwOtBfJg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9ae93a1-e3c6-49de-b841-9d6b3c36ac52"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLo5zlsqBoIH"
      },
      "source": [
        "wnl = WordNetLemmatizer() "
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtw9i0MZB2nP",
        "outputId": "960d3df4-c799-40b1-b89f-7d0a0965bc76"
      },
      "source": [
        "y = ['fall', 'fell', 'fallen', 'falling', 'feet', 'ring', 'rang', 'rung', 'ringing', 'come', 'came', 'coming', 'built', 'were', 'am', 'is']\n",
        "\n",
        "print([wnl.lemmatize(w) for w in y])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fall', 'fell', 'fallen', 'falling', 'foot', 'ring', 'rang', 'rung', 'ringing', 'come', 'came', 'coming', 'built', 'were', 'am', 'is']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C433zO21CZIH"
      },
      "source": [
        "###Observa que no llevó a cabo ninguna modificación, esto es porque requiere la información sintáctica de la palabra. \n",
        "\n",
        "###La opción predeterminada es \"noun\" (sustantivo).\n",
        "\n",
        "###En este caso que todos son verbos, veamos como esta información nos ayuda a obtener mejores resultados:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mg32oOSiCtIy",
        "outputId": "6717e7cb-ad6b-4474-afc8-e7d08d68dd1f"
      },
      "source": [
        "#verbs\n",
        "z = ['fall', 'fell', 'fallen', 'falling', 'feet', 'ring', 'rang', 'rung', 'ringing', 'come', 'came', 'coming', 'built', 'were', 'am', 'is']\n",
        "\n",
        "print([wnl.lemmatize(w, pos='v') for w in z])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fall', 'fell', 'fall', 'fall', 'feet', 'ring', 'ring', 'ring', 'ring', 'come', 'come', 'come', 'build', 'be', 'be', 'be']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDQehaJhC7iv",
        "outputId": "b6f6df04-2b07-480d-fa9b-faa536c5bc16"
      },
      "source": [
        "z = ['stranger', 'dogs', 'beautifully', 'amazing', 'whiter', 'terminator', 'carefully', 'eldest', 'farthest', 'further', 'queries', 'waterbed']\n",
        "# verbs\n",
        "print([wnl.lemmatize(w, 'v') for w in z])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['stranger', 'dog', 'beautifully', 'amaze', 'whiter', 'terminator', 'carefully', 'eldest', 'farthest', 'further', 'query', 'waterbed']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DrkmOQ4DQz_",
        "outputId": "158e12b8-9f56-4475-944f-bd17918f7f1a"
      },
      "source": [
        "# nouns\n",
        "z = ['languages', 'dogs', 'developer', 'nationalism', 'artist', 'government', 'happiness', 'championship', 'station']\n",
        "\n",
        "print([wnl.lemmatize(w, 'n') for w in z])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['language', 'dog', 'developer', 'nationalism', 'artist', 'government', 'happiness', 'championship', 'station']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNHBI19DDemg",
        "outputId": "a522131d-14fd-4297-8f96-24a274b32bd3"
      },
      "source": [
        "# adjectives\n",
        "z = ['tall', 'tallest', 'bigger', 'highest', 'ugliest', 'happier']\n",
        "\n",
        "print([wnl.lemmatize(w, 'a') for w in z])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tall', 'tall', 'big', 'high', 'ugly', 'happy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8f0_mOvgIkf",
        "outputId": "9ef05770-b287-4913-aefb-fffb84911f29"
      },
      "source": [
        "# adverbios\n",
        "z = ['openly', 'actually', 'better']\n",
        "\n",
        "print([wnl.lemmatize(w, 'r') for w in z])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['openly', 'actually', 'well']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Más adelante lo combinaremos con los métodos llamados POStag, que clasifica precisamente cada palabra como verbo, adjetivo, etc."
      ],
      "metadata": {
        "id": "VEkl6fkgI-1c"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNgfhho3q25H"
      },
      "source": [
        "## Comparación tabular:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UNG6YVbq6J8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c09be77e-c9d3-40ca-d90e-c0d578361216"
      },
      "source": [
        "print(\"{0:20}{1:20}{2:20}\".format(\"Word\",\"Porter Stemmer\",\"lancaster Stemmer\"))\n",
        "for word in y:\n",
        "    print(\"{0:20}{1:20}{2:20}\".format(word, ps.stem(word),ls.stem(word)))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word                Porter Stemmer      lancaster Stemmer   \n",
            "fall                fall                fal                 \n",
            "fell                fell                fel                 \n",
            "fallen              fallen              fal                 \n",
            "falling             fall                fal                 \n",
            "feet                feet                feet                \n",
            "ring                ring                ring                \n",
            "rang                rang                rang                \n",
            "rung                rung                rung                \n",
            "ringing             ring                ring                \n",
            "come                come                com                 \n",
            "came                came                cam                 \n",
            "coming              come                com                 \n",
            "built               built               built               \n",
            "were                were                wer                 \n",
            "am                  am                  am                  \n",
            "is                  is                  is                  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aunque existen algunas métricas que miden qué tanto se simplificó un documento con alguno de estos métodos, en la práctica es aplicar varios de ellos y observar cuál te da los mejores resultados en el análisis que estés realizando."
      ],
      "metadata": {
        "id": "vZOtWSGNLJvH"
      }
    }
  ]
}